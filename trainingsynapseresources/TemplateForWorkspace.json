{
	"$schema": "http://schema.management.azure.com/schemas/2015-01-01/deploymentTemplate.json#",
	"contentVersion": "1.0.0.0",
	"parameters": {
		"workspaceName": {
			"type": "string",
			"metadata": "Workspace name",
			"defaultValue": "trainingsynapseresources"
		},
		"trainingsynapseresources-WorkspaceDefaultSqlServer_connectionString": {
			"type": "secureString",
			"metadata": "Secure string for 'connectionString' of 'trainingsynapseresources-WorkspaceDefaultSqlServer'"
		},
		"trainingstoragev101_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://trainingstoragev101.dfs.core.windows.net/"
		},
		"trainingsynapseresources-WorkspaceDefaultStorage_properties_typeProperties_url": {
			"type": "string",
			"defaultValue": "https://synapsedlsv10.dfs.core.windows.net"
		}
	},
	"variables": {
		"workspaceId": "[concat('Microsoft.Synapse/workspaces/', parameters('workspaceName'))]"
	},
	"resources": [
		{
			"name": "[concat(parameters('workspaceName'), '/trainingstoragev101')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('trainingstoragev101_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/trainingsynapseresources-WorkspaceDefaultSqlServer')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"parameters": {
					"DBName": {
						"type": "String"
					}
				},
				"annotations": [],
				"type": "AzureSqlDW",
				"typeProperties": {
					"connectionString": "[parameters('trainingsynapseresources-WorkspaceDefaultSqlServer_connectionString')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/trainingsynapseresources-WorkspaceDefaultStorage')]",
			"type": "Microsoft.Synapse/workspaces/linkedServices",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"annotations": [],
				"type": "AzureBlobFS",
				"typeProperties": {
					"url": "[parameters('trainingsynapseresources-WorkspaceDefaultStorage_properties_typeProperties_url')]"
				},
				"connectVia": {
					"referenceName": "AutoResolveIntegrationRuntime",
					"type": "IntegrationRuntimeReference"
				}
			},
			"dependsOn": [
				"[concat(variables('workspaceId'), '/integrationRuntimes/AutoResolveIntegrationRuntime')]"
			]
		},
		{
			"name": "[concat(parameters('workspaceName'), '/AutoResolveIntegrationRuntime')]",
			"type": "Microsoft.Synapse/workspaces/integrationRuntimes",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "Managed",
				"typeProperties": {
					"computeProperties": {
						"location": "AutoResolve",
						"dataFlowProperties": {
							"computeType": "General",
							"coreCount": 8,
							"timeToLive": 0
						}
					}
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/TrainingDataFlowLibrary')]",
			"type": "Microsoft.Synapse/workspaces/dataflows",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "UDFLibrary",
				"typeProperties": {
					"sources": [],
					"sinks": [],
					"transformations": [],
					"scriptLines": [
						"ExConcat(string, string) as string = concat(i1,i2)"
					]
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/WorkspaceSystemIdentity')]",
			"type": "Microsoft.Synapse/workspaces/credentials",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"type": "ManagedIdentity",
				"typeProperties": {}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Delta Lake Exploration')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool001v1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "0c64b8f1-b44c-4bcb-8198-daa35f44e04b"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/924cf5c7-5f72-42ba-98ee-7ea905016982/resourceGroups/trainingresourcegroupv10/providers/Microsoft.Synapse/workspaces/trainingsynapseresources/bigDataPools/SparkPool001v1",
						"name": "SparkPool001v1",
						"type": "Spark",
						"endpoint": "https://trainingsynapseresources.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool001v1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"import random\r\n",
							"\r\n",
							"session_id = random.randint(1,1000000)\r\n",
							"delta_table_path = \"/delta-training/delta-table-{0}\".format(session_id)\r\n",
							"\r\n",
							"delta_table_path"
						],
						"outputs": [],
						"execution_count": 1
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"data = spark.range(0,10)\r\n",
							"data.show()\r\n",
							"\r\n",
							"data \\\r\n",
							"    .write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 2
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = spark \\\r\n",
							"    .read \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .load(delta_table_path)\r\n",
							"\r\n",
							"df.show()"
						],
						"outputs": [],
						"execution_count": 3
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"data = spark.range(10, 20)\r\n",
							"data \\\r\n",
							"    .write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .mode(\"overwrite\") \\\r\n",
							"    .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 4
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"data \\\r\n",
							"    .write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .saveAsTable(\"ManagedDeltaTablev2\")"
						],
						"outputs": [],
						"execution_count": 5
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"CREATE TABLE ExternalDeltaTablev2\r\n",
							"USING DELTA\r\n",
							"LOCATION '/delta-training/delta-table-645199'"
						],
						"outputs": [],
						"execution_count": 6
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"SHOW TABLES"
						],
						"outputs": [],
						"execution_count": 7
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							},
							"microsoft": {
								"language": "sparksql"
							},
							"collapsed": false
						},
						"source": [
							"%%sql\r\n",
							"\r\n",
							"DESCRIBE EXTENDED manageddeltatablev2"
						],
						"outputs": [],
						"execution_count": 8
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"print(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 9
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"from delta.tables import *\r\n",
							"from pyspark.sql.functions import *\r\n",
							"\r\n",
							"delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"delta_table.update(\r\n",
							"    condition = expr (\"id % 2 == 1\"),\r\n",
							"    set = { \"id\": expr(\"id + 100\")}\r\n",
							")\r\n",
							"\r\n",
							"delta_table.delete(\"id >= 9\")\r\n",
							"\r\n",
							"delta_table.toDF().show()"
						],
						"outputs": [],
						"execution_count": 10
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"data = spark.range(10, 20)\r\n",
							"data \\\r\n",
							"    .write \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .mode(\"overwrite\") \\\r\n",
							"    .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": 11
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"new_data = spark.range(15, 25)\r\n",
							"\r\n",
							"delta_table = DeltaTable.forPath(spark, delta_table_path)\r\n",
							"\r\n",
							"delta_table \\\r\n",
							"    .alias(\"oldData\") \\\r\n",
							"    .merge(new_data.alias(\"newData\"), \"oldData.id = newData.id\") \\\r\n",
							"    .whenMatchedUpdate(set = {'id': lit(-1)}) \\\r\n",
							"    .whenNotMatchedInsert(values = { 'id': col(\"newData.id\") }) \\\r\n",
							"    .execute()\r\n",
							"\r\n",
							"delta_table.toDF().show()"
						],
						"outputs": [],
						"execution_count": 15
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"delta_table \\\r\n",
							"    .history() \\\r\n",
							"    .show()"
						],
						"outputs": [],
						"execution_count": 16
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"df = spark \\\r\n",
							"    .read \\\r\n",
							"    .format (\"delta\") \\\r\n",
							"    .option(\"versionAsOf\", 0) \\\r\n",
							"    .load(delta_table_path)\r\n",
							"\r\n",
							"df.show()"
						],
						"outputs": [],
						"execution_count": 18
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"streaming_df = \\\r\n",
							"    spark \\\r\n",
							"        .readStream \\\r\n",
							"        .format(\"rate\") \\\r\n",
							"        .load()\r\n",
							"    \r\n",
							"stream = streaming_df \\\r\n",
							"    .selectExpr(\"value as id\") \\\r\n",
							"    .writeStream \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .option(\"checkpointLocation\", \"/tmp/checkpoint-{0}\".format(session_id)) \\\r\n",
							"    .start(delta_table_path)\r\n",
							"\r\n",
							"stream.status"
						],
						"outputs": [],
						"execution_count": 19
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"delta_table \\\r\n",
							"    .toDF() \\\r\n",
							"    .sort(col(\"id\").desc()) \\\r\n",
							"    .show(100)"
						],
						"outputs": [],
						"execution_count": 20
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"delta_table \\\r\n",
							"    .history() \\\r\n",
							"    .show()"
						],
						"outputs": [],
						"execution_count": 21
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"stream.stop()"
						],
						"outputs": [],
						"execution_count": 22
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"partition_count = 2\r\n",
							"\r\n",
							"spark \\\r\n",
							"    .read \\\r\n",
							"    .format(\"delta\") \\\r\n",
							"    .load(delta_table_path) \\\r\n",
							"    .repartition(partition_count) \\\r\n",
							"    .write \\\r\n",
							"    .option(\"dataChange\", \"false\") \\\r\n",
							"    .mode(\"overwrite\") \\\r\n",
							"    .save(delta_table_path)"
						],
						"outputs": [],
						"execution_count": null
					},
					{
						"cell_type": "code",
						"metadata": {
							"jupyter": {
								"source_hidden": false,
								"outputs_hidden": false
							},
							"nteract": {
								"transient": {
									"deleting": false
								}
							}
						},
						"source": [
							"spark.sql(\"DESCRIBE HISTORY ManagedDeltaTablev2\").show()"
						],
						"outputs": [],
						"execution_count": 26
					}
				]
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Training Spark Configuration')]",
			"type": "Microsoft.Synapse/workspaces/sparkConfigurations",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"configs": {
					"spark.buffer.size": "65536"
				},
				"created": "2022-06-23T10:14:52.9600000+05:30",
				"createdBy": "ramkumar@exonia64.onmicrosoft.com",
				"annotations": [],
				"configMergeRule": {
					"artifact.currentOperation.spark.buffer.size": "replace"
				}
			},
			"dependsOn": []
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SparkPool001v1')]",
			"type": "Microsoft.Synapse/workspaces/bigDataPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"autoPause": {
					"enabled": true,
					"delayInMinutes": 15
				},
				"autoScale": {
					"enabled": true,
					"maxNodeCount": 3,
					"minNodeCount": 3
				},
				"nodeCount": 0,
				"nodeSize": "Medium",
				"nodeSizeFamily": "MemoryOptimized",
				"sparkVersion": "3.1",
				"isComputeIsolationEnabled": false,
				"sessionLevelPackagesEnabled": true,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/SQLPool01v1')]",
			"type": "Microsoft.Synapse/workspaces/sqlPools",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"collation": "SQL_Latin1_General_CP1_CI_AS",
				"maxSizeBytes": 263882790666240,
				"annotations": []
			},
			"dependsOn": [],
			"location": "eastus"
		},
		{
			"name": "[concat(parameters('workspaceName'), '/Databricks - Query Performance with Parquet and Delta')]",
			"type": "Microsoft.Synapse/workspaces/notebooks",
			"apiVersion": "2019-06-01-preview",
			"properties": {
				"nbformat": 4,
				"nbformat_minor": 2,
				"bigDataPool": {
					"referenceName": "SparkPool001v1",
					"type": "BigDataPoolReference"
				},
				"sessionProperties": {
					"driverMemory": "56g",
					"driverCores": 8,
					"executorMemory": "56g",
					"executorCores": 8,
					"numExecutors": 2,
					"conf": {
						"spark.dynamicAllocation.enabled": "false",
						"spark.dynamicAllocation.minExecutors": "2",
						"spark.dynamicAllocation.maxExecutors": "2",
						"spark.autotune.trackingId": "ac0d0e02-2c2b-421e-b0b9-b346fb10963a"
					}
				},
				"metadata": {
					"saveOutput": true,
					"enableDebugMode": false,
					"kernelspec": {
						"name": "synapse_pyspark",
						"display_name": "Synapse PySpark"
					},
					"language_info": {
						"name": "python"
					},
					"a365ComputeOptions": {
						"id": "/subscriptions/924cf5c7-5f72-42ba-98ee-7ea905016982/resourceGroups/trainingresourcegroupv10/providers/Microsoft.Synapse/workspaces/trainingsynapseresources/bigDataPools/SparkPool001v1",
						"name": "SparkPool001v1",
						"type": "Spark",
						"endpoint": "https://trainingsynapseresources.dev.azuresynapse.net/livyApi/versions/2019-11-01-preview/sparkPools/SparkPool001v1",
						"auth": {
							"type": "AAD",
							"authResource": "https://dev.azuresynapse.net"
						},
						"sparkVersion": "3.1",
						"nodeCount": 3,
						"cores": 8,
						"memory": 56,
						"automaticScaleJobs": false
					},
					"sessionKeepAliveTimeout": 30
				},
				"cells": [
					{
						"cell_type": "code",
						"metadata": {},
						"source": [
							"from notebookutils import mssparkutils\r\n",
							"\r\n",
							"mssparkutils.fs.mount(\r\n",
							"    \"abfss://data@trainingstoragev101.dfs.core.windows.net/\",\r\n",
							"    \"/test\",\r\n",
							"    {\r\n",
							"        \"linkedService\": \"trainingstoragev101\"\r\n",
							"    }\r\n",
							")"
						],
						"outputs": [],
						"execution_count": 1
					}
				]
			},
			"dependsOn": []
		}
	]
}